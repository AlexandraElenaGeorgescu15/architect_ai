import streamlit as st
import pandas as pd
import json
from thefuzz import fuzz
from snowflake.snowpark.context import get_active_session
import time
import io
import altair as alt
import re, ast

# --------------------------------------------------------------------------
# 1. Page Configuration & Global Styling
# --------------------------------------------------------------------------
st.set_page_config(layout="wide", page_title="BOM Intelligence Agent", page_icon="ü§ñ")

# --- Custom Styling ---
st.markdown("""
<style>    
    .stApp {
        background-color: #0E1117;
    }
    h1, h2, h3 {
        color: #00A1FF; /* Electric Blue */
    }
    .stButton>button {
        border-radius: 20px;
        border: 2px solid #00A1FF;
        color: #00A1FF;
        background-color: transparent;
        transition: all 0.3s ease-in-out;
    }
    .stButton>button:hover {
        border-color: #A020F0; /* Purple */
        color: #A020F0;
        box-shadow: 0 0 10px #A020F0;
    }
    .stButton>button[kind="primary"] {
        background-color: #00A1FF;
        color: white;
    }
    .stButton>button[kind="primary"]:hover {
        background-color: #A020F0;
        border-color: #A020F0;
    }
    [data-testid="stMetric"] {
        background-color: #1A1C2A;
        border-left: 5px solid #00A1FF;
        border-radius: 8px;
        padding: 15px;
    }
</style>
""", unsafe_allow_html=True)

st.title("ü§ñ BOM Intelligence Agent")
st.caption(f"Project Chimera ‚Äî Your Agentic Co-Pilot for BOM Optimization | Status as of: {time.strftime('%d %b %Y, %H:%M')}")

# --------------------------------------------------------------------------
# 2. Agentic Workflow & Helper Functions
# --------------------------------------------------------------------------

# --- Functions for BOM Optimizer ---

def parse_attrs(attrs_str):
    """Robust JSON/Python-dict parser; no dumb quote-replace."""
    if attrs_str is None or (isinstance(attrs_str, float) and pd.isna(attrs_str)):
        return {}
    if isinstance(attrs_str, dict):
        return attrs_str
    if isinstance(attrs_str, (bytes, bytearray)):
        attrs_str = attrs_str.decode("utf-8", "ignore")
    s = str(attrs_str).strip()
    if not s:
        return {}

    # 1) Try strict JSON first
    try:
        return json.loads(s)
    except Exception:
        pass

    # 2) If wrapped in code fences or has extra junk, extract the first {...}
    m = re.search(r"\{.*\}", s, re.S)
    if m:
        blob = m.group(0)
        try:
            return json.loads(blob)
        except Exception:
            pass
        try:
            return ast.literal_eval(blob)  # handles single-quoted Python dicts
        except Exception:
            pass

    # 3) Last resort: Python literal (single quotes etc.)
    try:
        return ast.literal_eval(s)
    except Exception:
        return {}

def map_offer_columns(df):
    """Intelligently maps common column names to a standardized schema."""
    rename_map = {}
    found_cols = []
    df.columns = [str(c).lower().strip() for c in df.columns]
    column_aliases = {
        'MFG_PART': ['mfg_part', 'part_number', 'mpn', 'sku', 'manufacturer part number', 'type name', 'description', 'item', 'item name'],
        'VENDOR_ID': ['vendor_id', 'supplier', 'distributor', 'vendor'],
        'PRICE': ['price', 'cost', 'unit_price', 'price per unit'],
        'STOCK': ['stock', 'quantity', 'on_hand', 'qty'],
        'BRAND': ['brand', 'manufacturer', 'mfg'],
        'ATTRS': ['attrs', 'attributes', 'specs', 'specifications']
    }
    for standard_name, aliases in column_aliases.items():
        for alias in aliases:
            if alias in df.columns:
                rename_map[alias] = standard_name
                if standard_name not in found_cols:
                    found_cols.append(standard_name)
    df.rename(columns=rename_map, inplace=True)
    return df, found_cols

@st.cache_data(show_spinner=False)
def extract_attributes_with_llm(_session, part_number, manufacturer, other_cols_json):
    prompt = f"""
    You are an expert in MEP parts, specializing in data harmonization.
    Return ONLY a single JSON object (no prose, no code fences, no markdown).
    Use EXACT keys: "part_type", "shape", "primary_dimension", "secondary_dimension", "angle", "reasoning".
    Use double quotes for all JSON strings. Use numbers for dimensions or null.
    If uncertain, keep fields as null but STILL include a short "reasoning".

    Component Data:
    - Type Name: "{part_number}"
    - Manufacturer: "{manufacturer}"
    - Other Data: {other_cols_json}
    """

    sql_command = f"SELECT SNOWFLAKE.CORTEX.COMPLETE('snowflake-arctic', $${prompt}$$) AS llm_response"
    try:
        response_df = _session.sql(sql_command).to_pandas()
        raw = str(response_df['LLM_RESPONSE'][0]).strip()

        # Remove potential code fences
        raw = raw.replace("```json", "```")
        if raw.startswith("```") and raw.endswith("```"):
            raw = raw[3:-3].strip()

        # Extract the JSON blob and parse robustly
        m = re.search(r"\{.*\}", raw, re.S)
        blob = m.group(0) if m else raw
        data = parse_attrs(blob)

        # Normalize keys (just in case model slips camelCase)
        key_map = {
            "part_type": "part_type",
            "shape": "shape",
            "primary_dimension": "primary_dimension",
            "secondary_dimension": "secondary_dimension",
            "angle": "angle",
            "reasoning": "reasoning",
            "primaryDimension": "primary_dimension",
            "secondaryDimension": "secondary_dimension",
            "PartType": "part_type",
            "Shape": "shape",
            "Reasoning": "reasoning",
        }
        norm = {}
        for k, v in (data if isinstance(data, dict) else {}).items():
            norm[key_map.get(k, k)] = v

        # Coerce numerics / clean empties
        for k in ("primary_dimension", "secondary_dimension", "angle"):
            if k in norm:
                try:
                    if norm[k] in ("", None):
                        norm[k] = None
                    else:
                        norm[k] = float(str(norm[k]).replace(",", ""))
                except Exception:
                    norm[k] = None

        # Ensure all keys exist
        for k in ("part_type", "shape", "primary_dimension", "secondary_dimension", "angle", "reasoning"):
            norm.setdefault(k, None)

        return json.dumps(norm)
    except Exception:
        return "{}"

def preprocess_bom_data(df, session):
    """The core data harmonization step with intelligent quantity aggregation."""
    st.markdown("---")
    st.subheader("üß† Step 2: AI-Powered Data Harmonization & Quantity Aggregation")
    st.info("The agent is aggregating duplicate rows in your BOM to calculate total quantities needed, then interpreting part names into standard engineering attributes. This ensures accurate stock checking against supplier inventory.")
    
    df_processed = df.copy()
    rename_map = {'Type Name': 'PART_NUMBER', 'Manufacturer': 'MANUFACTURER', 'ElementId': 'LINE_ID'}
    df_processed.rename(columns=rename_map, inplace=True)
    if 'MANUFACTURER' not in df_processed.columns:
        df_processed['MANUFACTURER'] = 'Generic'
    else:
        df_processed['MANUFACTURER'] = df_processed['MANUFACTURER'].fillna('Generic')
    
    # Store original row IDs before aggregation
    df_processed['ORIGINAL_LINE_IDS'] = df_processed.get('LINE_ID', df_processed.index.astype(str))
    
    # Aggregate duplicate rows to get total quantities needed
    attr_cols = ['Angle', 'Diameter', 'Width', 'Height', 'Length', 'Size']
    cols_to_pass = [col for col in attr_cols if col in df_processed.columns]
    
    # Group by PART_NUMBER and MANUFACTURER to aggregate quantities
    agg_dict = {'ORIGINAL_LINE_IDS': lambda x: ', '.join(map(str, x))}
    for col in cols_to_pass:
        agg_dict[col] = 'first'  # Take first value for attributes
    
    df_aggregated = df_processed.groupby(['PART_NUMBER', 'MANUFACTURER']).agg(agg_dict).reset_index()
    df_aggregated['QUANTITY'] = df_processed.groupby(['PART_NUMBER', 'MANUFACTURER']).size().values
    
    st.success(f"‚úÖ **Aggregated {len(df_processed)} BOM rows into {len(df_aggregated)} unique parts**")
    
    # Show aggregation summary
    st.info("üìä View Quantity Aggregation Details")
    qty_summary = df_aggregated[['PART_NUMBER', 'MANUFACTURER', 'QUANTITY']].sort_values('QUANTITY', ascending=False)
    st.dataframe(qty_summary, use_container_width=True)
    
    # Now perform AI harmonization on unique parts only
    progress_bar = st.progress(0, text="Initializing AI analysis...")
    status_text = st.empty()
    
    for i, row in df_aggregated.iterrows():
        status_text.markdown(f"üß† Analyzing component {i+1}/{len(df_aggregated)}: *`{row['PART_NUMBER']}`* (Qty: {row['QUANTITY']})")
        other_data = row[cols_to_pass].to_json() if cols_to_pass else "{}"
        
        # Extract attributes and reasoning from LLM
        attrs_json_str = extract_attributes_with_llm(session, row['PART_NUMBER'], row['MANUFACTURER'], other_data)
        attrs_dict = parse_attrs(attrs_json_str)
        
        # Pop reasoning but handle if it's missing
        reasoning = attrs_dict.pop('reasoning', None)
        if not reasoning:
            extracted_attrs = {k: v for k, v in attrs_dict.items() if v is not None}
            if extracted_attrs:
                reasoning = f"Aggregated {row['QUANTITY']} instances. Attributes: {json.dumps(extracted_attrs)}."
            else:
                reasoning = f"Aggregated {row['QUANTITY']} instances from BOM rows: {row['ORIGINAL_LINE_IDS'][:100]}..."
        
        df_aggregated.loc[i, 'HARMONIZATION_REASONING'] = reasoning
        df_aggregated.loc[i, 'ATTRS'] = json.dumps(attrs_dict)

        progress_bar.progress((i + 1) / len(df_aggregated))
        
    status_text.success("ü§ñ **Harmonization complete!**")
    return df_aggregated

@st.cache_data
def calculate_best_offers(_df_bom, _df_offers, weights):
    """Performs intelligent matching with smart routing and stock management."""
    df_bom = _df_bom.copy()
    df_offers = _df_offers.copy()
    all_results = []
    preferred_brands = ['Geberit', 'MEPcontent']
    
    df_bom['part_number_upper'] = df_bom['PART_NUMBER'].astype(str).str.upper()
    df_offers['mfg_part_upper'] = df_offers.get('MFG_PART', pd.Series(dtype=str)).astype(str).str.upper()

    progress_bar = st.progress(0, text="Searching for optimal supplier offers with intelligent stock routing...")
    
    for i, bom_row in df_bom.iterrows():
        candidates = []
        bom_attrs = parse_attrs(bom_row['ATTRS'])
        qty_needed = bom_row['QUANTITY']
        
        # Find all matching candidates
        for _, offer_row in df_offers.iterrows():
            score = fuzz.ratio(bom_row['part_number_upper'], offer_row.get('mfg_part_upper', ''))
            if score >= 85:
                cand = offer_row.to_dict()
                cand.update({'match_type': 'FUZZY', 'match_score': score})
                cand['supplier_stock'] = cand.get('STOCK', 0)  # Keep original stock
                candidates.append(cand)

        # Mark exact matches
        for cand in candidates:
            if cand.get('mfg_part_upper') == bom_row['part_number_upper']:
                cand['match_type'] = 'EXACT'
                cand['match_score'] = 101
        
        if candidates:
            max_price = max((c.get('PRICE', 0) for c in candidates if c.get('PRICE', 0) > 0), default=1)
            
            # Score each candidate
            for cand in candidates:
                offer_attrs = parse_attrs(cand.get('ATTRS', '{}'))
                pen_dim1 = 100 if bom_attrs.get('primary_dimension') != offer_attrs.get('primary_dimension') else 0
                pen_dim2 = 100 if bom_attrs.get('secondary_dimension') != offer_attrs.get('secondary_dimension') else 0
                
                # Stock availability: penalty if insufficient
                supplier_stock = cand['supplier_stock']
                stock_deficit = max(0, qty_needed - supplier_stock)
                oos_penalty = (stock_deficit / qty_needed) * 2.0 if qty_needed > 0 else 0
                
                brand_penalty = 0.2 if cand.get('BRAND') not in preferred_brands else 0
                price_norm = cand.get('PRICE', 0) / max_price if max_price > 0 else 0
                
                cand['final_score'] = ( (weights.get('price', 0.5) * price_norm) +
                                        (weights.get('stock', 0.2) * oos_penalty) +
                                        (weights.get('brand', 0.1) * brand_penalty) +
                                        pen_dim1 + pen_dim2 - (cand['match_score'] / 1000) )
                
                # Calculate actual quantities
                cand['qty_available'] = supplier_stock
                cand['qty_to_order'] = min(qty_needed, supplier_stock)
                cand['qty_shortfall'] = max(0, qty_needed - supplier_stock)
                cand['stock_status'] = 'SUFFICIENT' if supplier_stock >= qty_needed else 'INSUFFICIENT'
            
            # Select best primary offer
            winner = min(candidates, key=lambda x: x['final_score'])
            
            # Smart routing: find alternatives for shortfall
            in_stock_alternative = None
            split_order_alternatives = []
            
            if winner['stock_status'] == 'INSUFFICIENT':
                # Try to find a single supplier with sufficient stock
                sufficient_candidates = [c for c in candidates if c['qty_available'] >= qty_needed]
                if sufficient_candidates:
                    in_stock_alternative = min(sufficient_candidates, key=lambda x: x['final_score'])
                else:
                    # Smart split order routing: find combination of suppliers
                    remaining_qty = winner['qty_shortfall']
                    used_vendors = [winner.get('VENDOR_ID')]
                    
                    for cand in sorted(candidates, key=lambda x: x['final_score']):
                        if cand.get('VENDOR_ID') not in used_vendors and cand['qty_available'] > 0:
                            split_order_alternatives.append({
                                'vendor': cand.get('VENDOR_ID'),
                                'part': cand.get('MFG_PART'),
                                'price': cand.get('PRICE'),
                                'qty_available': cand['qty_available'],
                                'qty_to_order': min(remaining_qty, cand['qty_available']),
                                'match_score': cand['match_score']
                            })
                            used_vendors.append(cand.get('VENDOR_ID'))
                            remaining_qty -= min(remaining_qty, cand['qty_available'])
                            
                            if remaining_qty <= 0:
                                break

            result_row = bom_row.add_prefix('bom_').to_dict()
            result_row.update(winner)
            result_row['in_stock_alternative'] = in_stock_alternative
            result_row['split_order_options'] = split_order_alternatives if split_order_alternatives else None
            all_results.append(result_row)
        
        progress_bar.progress((i + 1) / len(df_bom))
        
    return pd.DataFrame(all_results)

@st.cache_data
def calculate_baseline_cost(_df_bom, _df_offers):
    """
    Calculates the baseline cost using only exact part number matches.
    
    IMPORTANT: This takes the LOWEST PRICE among exact matches to be conservative.
    If 3 vendors all have the same part at $23, we only count it once at $23.
    
    Formula: Sum of (Lowest Exact Match Price √ó BOM Quantity) for each unique part
    """
    # Merge BOM with offers on exact part number match
    merged_df = pd.merge(_df_bom, _df_offers, left_on='PART_NUMBER', right_on='MFG_PART', how='left')
    
    # CRITICAL FIX: If multiple vendors sell the same part, the merge creates duplicate rows
    # Example: BOM has "Part A" qty=5, and 3 vendors all sell "Part A" at $23 each
    #   Without this fix: 5√ó$23 + 5√ó$23 + 5√ó$23 = $345 (WRONG - triple counting!)
    #   With this fix: 5√ó$23 = $115 (CORRECT - one per BOM item)
    # Solution: Group by PART_NUMBER and keep only the cheapest price for each
    merged_df = merged_df.sort_values('PRICE').groupby('PART_NUMBER', as_index=False).first()
    
    # Calculate cost for items that have an exact match with a valid price
    merged_df['item_cost'] = merged_df.apply(
        lambda row: row['PRICE'] * row['QUANTITY'] if pd.notna(row['PRICE']) else 0, 
        axis=1
    )
    
    return merged_df['item_cost'].sum()

@st.cache_data
def get_ai_summary(_session, kpi_data):
    """Generates a concise executive summary of the results."""
    prompt = f"""
    You are a construction project analyst. Based on the following BOM optimization KPIs, executive summary.
    Focus on the business impact: cost savings and supply chain risk (delays).
    **KPI Data:**
    {json.dumps(kpi_data, indent=2)}
    """
    sql_command = f"SELECT SNOWFLAKE.CORTEX.COMPLETE('snowflake-arctic', $${prompt}$$) AS summary"
    try:
        response_df = _session.sql(sql_command).to_pandas()
        return response_df['SUMMARY'][0]
    except Exception:
        return "AI summary could not be generated."

# --- Helper Functions for UI and Data ---
def to_csv(df):
    """Converts a DataFrame to a UTF-8 encoded CSV file for download."""
    return df.to_csv(index=False).encode('utf-8')

def format_chat_history(messages):
    """Formats chat history for text file download."""
    history = []
    for message in messages:
        history.append(f"{message['role'].title()}:\n{message['content']}\n")
    return "\n".join(history)

def display_kpis(results_df, baseline_cost, lead_time, initial_cost=None):
    """Renders the main KPI dashboard with enhanced visualizations."""
    # Calculate total cost based on actual quantities to be ordered
    results_df['actual_cost'] = results_df.apply(
        lambda row: row['PRICE'] * row.get('qty_to_order', row['bom_QUANTITY']), 
        axis=1
    )
    total_cost = results_df['actual_cost'].sum()
    oos_count = results_df[results_df['stock_status'] == 'INSUFFICIENT'].shape[0]
    savings = baseline_cost - total_cost
    savings_percent = (savings / baseline_cost * 100) if baseline_cost > 0 else 0
    delay_risk_days = oos_count * lead_time

    # Main KPI Row
    kpi1, kpi2, kpi3, kpi4 = st.columns(4)
    kpi1.metric("Optimized BOM Cost", f"${total_cost:,.2f}",
                delta=f"{((total_cost - initial_cost) / initial_cost) * 100:.1f}% vs. Initial" if initial_cost else None,
                delta_color="inverse", help="Total cost of the currently proposed BOM.")
    
    kpi2.metric("‚úÖ Estimated Savings", f"${savings:,.2f}",
                f"{savings_percent:.1f}% vs. Baseline",
                help=f"Baseline cost (exact matches only) was ${baseline_cost:,.2f}. Savings are from AI-suggested alternatives.")

    if oos_count > 0:
        kpi3.metric("‚ö†Ô∏è STOCK ALERT", f"{oos_count} Items", help="Number of items with insufficient stock.")
        kpi4.metric("üìà PROJECT DELAY RISK", f"{delay_risk_days} Days",
                    help=f"Estimated delay risk: {oos_count} OOS items √ó {lead_time} days avg. lead time.")
    else:
        kpi3.metric("‚úÖ STOCK STATUS", "All Items In Stock", help="No immediate stock shortages.")
        kpi4.metric("üìà PROJECT DELAY RISK", "0 Days", delta="Risk Mitigated", delta_color="off",
                    help="Delay risk resolved by applying in-stock alternatives.")
    
    # Enhanced Visualizations
    st.markdown("---")
    
    # Cost Comparison Chart
    col1, col2 = st.columns([3, 2])
    
    with col1:
        st.markdown("#### üí∞ Cost Breakdown: Baseline vs. Optimized")
        cost_comparison_data = pd.DataFrame({
            'Category': ['Baseline Cost\n(Exact Matches)', 'Optimized Cost\n(AI Suggested)', 'Total Savings'],
            'Amount': [baseline_cost, total_cost, savings],
            'Type': ['Cost', 'Cost', 'Savings']
        })
        
        chart = alt.Chart(cost_comparison_data).mark_bar(
            cornerRadiusTopLeft=5,
            cornerRadiusTopRight=5
        ).encode(
            x=alt.X('Category:N', title=None, axis=alt.Axis(labelAngle=0)),
            y=alt.Y('Amount:Q', title='Amount ($)', axis=alt.Axis(format='$,.0f')),
            color=alt.Color('Type:N', 
                          scale=alt.Scale(domain=['Cost', 'Savings'], 
                                        range=['#00A1FF', '#00FF88']),
                          legend=None),
            tooltip=[
                alt.Tooltip('Category:N', title='Category'),
                alt.Tooltip('Amount:Q', title='Amount', format='$,.2f')
            ]
        ).properties(height=300)
        
        st.altair_chart(chart, use_container_width=True)
    
    with col2:
        st.markdown("#### üéØ Match Type Distribution")
        
        # Count match types
        exact_matches = len(results_df[results_df['match_type'] == 'EXACT'])
        fuzzy_matches = len(results_df[results_df['match_type'] == 'FUZZY'])
        
        match_data = pd.DataFrame({
            'Match Type': ['Exact Match', 'AI Suggested'],
            'Count': [exact_matches, fuzzy_matches],
            'Percentage': [
                (exact_matches / len(results_df) * 100) if len(results_df) > 0 else 0,
                (fuzzy_matches / len(results_df) * 100) if len(results_df) > 0 else 0
            ]
        })
        
        pie_chart = alt.Chart(match_data).mark_arc(innerRadius=50).encode(
            theta=alt.Theta('Count:Q'),
            color=alt.Color('Match Type:N',
                          scale=alt.Scale(domain=['Exact Match', 'AI Suggested'],
                                        range=['#00A1FF', '#A020F0']),
                          legend=alt.Legend(title='Match Type')),
            tooltip=[
                alt.Tooltip('Match Type:N'),
                alt.Tooltip('Count:Q'),
                alt.Tooltip('Percentage:Q', format='.1f', title='Percentage (%)')
            ]
        ).properties(height=300)
        
        st.altair_chart(pie_chart, use_container_width=True)
    
    # Savings Breakdown with Enhanced Visualization
    st.markdown("#### üí° Savings Insight & AI Impact")
    
    # Create an info box explaining the difference
    st.info("""
    **How are savings calculated?**
    - **Baseline Cost**: Sum of (Exact Match Price √ó Quantity) for all parts where part numbers match exactly
    - **Optimized Cost**: Sum of (Best Offer Price √ó Quantity) using AI fuzzy matching (85%+ similarity) and multi-factor scoring
    - **Savings**: The difference shows how much money AI optimization saves by finding better alternatives
    """)
    
    col3, col4, col5 = st.columns(3)
    
    avg_savings_per_item = savings / len(results_df) if len(results_df) > 0 else 0
    col3.metric("Avg Savings Per Item", f"${avg_savings_per_item:,.2f}", 
                help="Average cost reduction per line item")
    
    roi_percentage = (savings / baseline_cost * 100) if baseline_cost > 0 else 0
    col4.metric("ROI on AI Optimization", f"{roi_percentage:.1f}%", 
                help="Return on investment from using AI matching")
    
    items_with_savings = len(results_df[results_df['match_type'] == 'FUZZY'])
    col5.metric("Items Optimized", f"{items_with_savings}", 
                help="Number of items where AI found better alternatives")
    
    # Savings Gauge Visualization
    st.markdown("#### üìä Savings Performance Gauge")
    gauge_col1, gauge_col2 = st.columns([2, 1])
    
    with gauge_col1:
        # Create a gauge-like visualization using a horizontal bar
        gauge_data = pd.DataFrame({
            'Category': ['Savings'],
            'Percentage': [min(savings_percent, 100)]  # Cap at 100%
        })
        
        # Color coding based on savings percentage
        if savings_percent >= 20:
            gauge_color = '#00FF88'  # Green
            performance = "üåü Exceptional"
        elif savings_percent >= 10:
            gauge_color = '#00A1FF'  # Blue
            performance = "‚úÖ Great"
        elif savings_percent >= 5:
            gauge_color = '#FFA500'  # Orange
            performance = "üëç Good"
        else:
            gauge_color = '#FF6B6B'  # Red
            performance = "‚ö†Ô∏è Modest"
        
        gauge_chart = alt.Chart(gauge_data).mark_bar(
            cornerRadiusTopLeft=10,
            cornerRadiusBottomLeft=10,
            cornerRadiusTopRight=10,
            cornerRadiusBottomRight=10,
            height=40
        ).encode(
            x=alt.X('Percentage:Q', 
                   scale=alt.Scale(domain=[0, 100]),
                   axis=alt.Axis(title='Savings Percentage (%)', format='.0f')),
            color=alt.value(gauge_color),
            tooltip=[alt.Tooltip('Percentage:Q', format='.1f', title='Savings %')]
        ).properties(height=80)
        
        st.altair_chart(gauge_chart, use_container_width=True)
    
    with gauge_col2:
        st.markdown(f"""
        <div style='text-align: center; padding: 20px; background-color: #1A1C2A; border-radius: 10px; border-left: 5px solid {gauge_color};'>
            <h2 style='color: {gauge_color}; margin: 0;'>{savings_percent:.1f}%</h2>
            <p style='color: #FFFFFF; margin: 5px 0;'>{performance}</p>
            <p style='color: #888888; font-size: 0.9em; margin: 0;'>Optimization Score</p>
        </div>
        """, unsafe_allow_html=True)
    
    # Stock Analysis Section
    st.markdown("---")
    st.markdown("#### üì¶ Stock Availability Analysis")
    
    stock_col1, stock_col2 = st.columns(2)
    
    with stock_col1:
        # Stock status breakdown
        st.markdown("**Stock Status Distribution**")
        sufficient_count = len(results_df[results_df['stock_status'] == 'SUFFICIENT'])
        insufficient_count = len(results_df[results_df['stock_status'] == 'INSUFFICIENT'])
        
        stock_status_data = pd.DataFrame({
            'Status': ['Sufficient Stock', 'Insufficient Stock'],
            'Count': [sufficient_count, insufficient_count],
            'Percentage': [
                (sufficient_count / len(results_df) * 100) if len(results_df) > 0 else 0,
                (insufficient_count / len(results_df) * 100) if len(results_df) > 0 else 0
            ]
        })
        
        stock_pie = alt.Chart(stock_status_data).mark_arc(innerRadius=50).encode(
            theta=alt.Theta('Count:Q'),
            color=alt.Color('Status:N',
                          scale=alt.Scale(domain=['Sufficient Stock', 'Insufficient Stock'],
                                        range=['#00FF88', '#FF6B6B']),
                          legend=alt.Legend(title='Stock Status')),
            tooltip=[
                alt.Tooltip('Status:N'),
                alt.Tooltip('Count:Q'),
                alt.Tooltip('Percentage:Q', format='.1f', title='Percentage (%)')
            ]
        ).properties(height=250)
        
        st.altair_chart(stock_pie, use_container_width=True)
    
    with stock_col2:
        # Top items with stock shortfalls
        st.markdown("**Top Stock Shortfalls**")
        shortfall_items = results_df[results_df['qty_shortfall'] > 0].copy()
        
        if len(shortfall_items) > 0:
            shortfall_items = shortfall_items.nlargest(10, 'qty_shortfall')[
                ['bom_PART_NUMBER', 'bom_QUANTITY', 'qty_available', 'qty_shortfall']
            ]
            
            shortfall_chart = alt.Chart(shortfall_items.head(5)).mark_bar().encode(
                y=alt.Y('bom_PART_NUMBER:N', sort='-x', title='Part Number'),
                x=alt.X('qty_shortfall:Q', title='Quantity Short'),
                color=alt.value('#FF6B6B'),
                tooltip=[
                    alt.Tooltip('bom_PART_NUMBER:N', title='Part'),
                    alt.Tooltip('bom_QUANTITY:Q', title='Needed'),
                    alt.Tooltip('qty_available:Q', title='Available'),
                    alt.Tooltip('qty_shortfall:Q', title='Shortfall')
                ]
            ).properties(height=250)
            
            st.altair_chart(shortfall_chart, use_container_width=True)
        else:
            st.success("‚úÖ All items have sufficient stock!")
    
    # Quantity fulfillment analysis
    st.markdown("#### üìä Quantity Fulfillment Overview")
    
    total_qty_needed = results_df['bom_QUANTITY'].sum()
    total_qty_available = results_df['qty_to_order'].sum()
    fulfillment_rate = (total_qty_available / total_qty_needed * 100) if total_qty_needed > 0 else 0
    
    fulfill_col1, fulfill_col2, fulfill_col3 = st.columns(3)
    fulfill_col1.metric("Total Units Needed", f"{int(total_qty_needed)}", help="Total quantity across all BOM items")
    fulfill_col2.metric("Units Available", f"{int(total_qty_available)}", 
                       delta=f"{int(total_qty_available - total_qty_needed)} units" if total_qty_available != total_qty_needed else None,
                       delta_color="normal", help="Total quantity that can be fulfilled from suppliers")
    fulfill_col3.metric("Fulfillment Rate", f"{fulfillment_rate:.1f}%", 
                       delta="Complete" if fulfillment_rate == 100 else "Shortfall",
                       delta_color="normal", help="Percentage of BOM that can be fulfilled")
    
    # Top Savings Contributors (only show if there are AI-suggested matches)
    if items_with_savings > 0:
        st.markdown("---")
        st.markdown("#### üèÜ Top 10 Cost Savings Contributors")
        
        # Calculate per-item savings (would need baseline prices for exact calculation)
        # For now, we'll show the optimized items sorted by total cost impact
        top_items = results_df[results_df['match_type'] == 'FUZZY'].copy()
        top_items['total_item_cost'] = top_items['PRICE'] * top_items['bom_QUANTITY']
        
        # Select only columns that exist
        desired_cols = ['bom_PART_NUMBER', 'MFG_PART', 'VENDOR_ID', 'PRICE', 'bom_QUANTITY', 'total_item_cost', 'match_score']
        available_cols = [col for col in desired_cols if col in top_items.columns]
        top_items = top_items.nlargest(10, 'total_item_cost')[available_cols]
        
        # Create a horizontal bar chart
        top_items_chart_data = top_items.copy()
        top_items_chart_data['Part'] = top_items_chart_data['bom_PART_NUMBER'].str[:30]  # Truncate long names
        
        # Build tooltip list dynamically based on available columns
        tooltip_list = [
            alt.Tooltip('bom_PART_NUMBER:N', title='BOM Part'),
            alt.Tooltip('MFG_PART:N', title='Matched Part')
        ]
        if 'VENDOR_ID' in top_items_chart_data.columns:
            tooltip_list.append(alt.Tooltip('VENDOR_ID:N', title='Vendor'))
        tooltip_list.extend([
            alt.Tooltip('PRICE:Q', format='$,.2f', title='Unit Price'),
            alt.Tooltip('bom_QUANTITY:Q', title='Quantity'),
            alt.Tooltip('total_item_cost:Q', format='$,.2f', title='Total Cost'),
            alt.Tooltip('match_score:Q', format='.0f', title='Match Score')
        ])
        
        chart = alt.Chart(top_items_chart_data).mark_bar(
            cornerRadiusTopRight=5,
            cornerRadiusBottomRight=5
        ).encode(
            y=alt.Y('Part:N', sort='-x', title=None),
            x=alt.X('total_item_cost:Q', title='Total Cost ($)', axis=alt.Axis(format='$,.0f')),
            color=alt.Color('match_score:Q',
                          scale=alt.Scale(scheme='viridis'),
                          legend=alt.Legend(title='Match Score')),
            tooltip=tooltip_list
        ).properties(height=350)
        
        st.altair_chart(chart, use_container_width=True)
        
        st.info("üìã View Detailed Table")
        display_top_items = top_items.copy()
        
        # Format numeric columns
        if 'PRICE' in display_top_items.columns:
            display_top_items['PRICE'] = display_top_items['PRICE'].apply(lambda x: f"${x:,.2f}")
        if 'total_item_cost' in display_top_items.columns:
            display_top_items['total_item_cost'] = display_top_items['total_item_cost'].apply(lambda x: f"${x:,.2f}")
        if 'match_score' in display_top_items.columns:
            display_top_items['match_score'] = display_top_items['match_score'].apply(lambda x: f"{x:.0f}%")
        
        # Rename columns dynamically based on what exists
        column_rename_map = {
            'bom_PART_NUMBER': 'BOM Part',
            'MFG_PART': 'Matched Part',
            'VENDOR_ID': 'Vendor',
            'PRICE': 'Unit Price',
            'bom_QUANTITY': 'Qty',
            'total_item_cost': 'Total Cost',
            'match_score': 'Match %'
        }
        
        # Only rename columns that exist
        display_top_items.rename(columns={k: v for k, v in column_rename_map.items() if k in display_top_items.columns}, inplace=True)
        
        st.dataframe(display_top_items, use_container_width=True, hide_index=True)

# --- Functions for Document Q&A ---
@st.cache_data
def get_doc_chat_response(_session, document_text, query):
    """Gets a response from the LLM based on document context."""
    # Truncate document to avoid exceeding token limits for the LLM prompt
    max_chars = 15000
    truncated = False
    if len(document_text) > max_chars:
        document_text = document_text[:max_chars]
        truncated = True

    prompt = f"""
    You are an AI assistant specializing in document analysis. Answer the user's question based EXCLUSIVELY on the provided document context. Be concise and to the point.
    **DOCUMENT CONTEXT:** --- {document_text} ---
    **USER QUESTION:** "{query}"
    **ANSWER:**
    """
    sql_command = f"SELECT SNOWFLAKE.CORTEX.COMPLETE('snowflake-arctic', $${prompt}$$) AS response"
    try:
        response_df = _session.sql(sql_command).to_pandas()
        response_text = response_df['RESPONSE'][0]
        # Prepend a warning to the user if the context was truncated
        if truncated:
            warning_message = (
                "‚ö†Ô∏è **Note:** The provided document was too long for a single analysis. "
                f"Only the first {max_chars} characters were considered by the AI. "
                "For comprehensive analysis of large documents, please focus on specific sections.\n\n---\n\n"
            )
            return warning_message + response_text
        return response_text
    except Exception as e:
        return f"Error processing request: {e}"

# --- Functions for Compliance Sentinel ---
@st.cache_data(show_spinner=False)
def check_compliance_with_llm(_session, component_data_json, rule):
    """Uses LLM to check if a component violates a rule."""
    prompt = f"""
    You are an AI compliance agent for construction projects. Your task is to determine if a given building component violates a specific rule.
    Respond ONLY with a JSON object containing two keys: "compliant" (boolean) and "reasoning" (a string explaining your decision, max 20 words).

    **Component Data:**
    {component_data_json}

    **Rule to Check:**
    "{rule}"

    Does this component violate the rule?
    """
    sql_command = f"SELECT SNOWFLAKE.CORTEX.COMPLETE('snowflake-arctic', $${prompt}$$) AS response"
    try:
        response_df = _session.sql(sql_command).to_pandas()
        llm_json_str = response_df['RESPONSE'][0]
        start = llm_json_str.find('{')
        end = llm_json_str.rfind('}') + 1
        return json.loads(llm_json_str[start:end]) if start != -1 and end != 0 else {"compliant": True, "reasoning": "Error parsing AI response."}
    except Exception:
        return {"compliant": True, "reasoning": "Could not execute compliance check."}

@st.cache_data
def run_compliance_check(_session, _bom_df, rules_text):
    """Iterates through BOM and rules to generate a compliance report."""
    bom_df = _bom_df.copy()
    rules = [rule.strip() for rule in rules_text.split('\n') if rule.strip()]
    violations = []
    
    progress_bar = st.progress(0, text="Initializing compliance scan...")
    total_checks = len(bom_df) * len(rules)

    for i, bom_row in bom_df.iterrows():
        for rule in rules:
            progress_bar.progress((i * len(rules) + rules.index(rule) + 1) / total_checks,
                                  text=f"Checking '{bom_row['bom_PART_NUMBER']}' against rule '{rule[:30]}...'")
            
            component_data = {
                "part_number": bom_row['bom_PART_NUMBER'],
                "manufacturer": bom_row['bom_MANUFACTURER'],
                "attributes": parse_attrs(bom_row['bom_ATTRS'])
            }
            component_json = json.dumps(component_data, indent=2)
            
            result = check_compliance_with_llm(_session, component_json, rule)
            if not result['compliant']:
                violations.append({
                    "Component": bom_row['bom_PART_NUMBER'],
                    "Rule Violated": rule,
                    "AI Reasoning": result['reasoning'],
                    "Line ID": bom_row.get('bom_LINE_ID', 'N/A')
                })
    return pd.DataFrame(violations)

# --------------------------------------------------------------------------
# 3. Main Application UI
# --------------------------------------------------------------------------

# --- Session State Initialization ---
if 'analysis_run' not in st.session_state:
    st.session_state.analysis_run = False
    st.session_state.initial_results = None
    st.session_state.final_results = None
    st.session_state.baseline_cost = 0
    st.session_state.ai_summary = ""
    st.session_state.bom_harmonized = None
if 'doc_messages' not in st.session_state:
    st.session_state.doc_messages = []
if 'doc_context' not in st.session_state:
    st.session_state.doc_context = ""
if 'compliance_results' not in st.session_state:
    st.session_state.compliance_results = None

# --- Main UI Tabs ---
tab1, tab2, tab3 = st.tabs(["ü§ñ BOM Optimizer", "üìÑ Document Q&A", "üõ°Ô∏è Compliance Sentinel"])

with tab1:
    # --- Step 1: File Upload & Configuration ---
    st.subheader("üìÇ Step 1: Ingest Data & Configure Agent")
    st.info("""
        1.  **Upload Your BOM:** Exported from CAD/Revit software (must contain 'Type Name').
        2.  **Upload Vendor Offers:** Supplier parts list (must contain part number and price).
        3.  **Configure the Agent:** Use the sidebar to set project priorities.
        4.  **Run Analysis:** The agent will harmonize data, find best offers, and present an optimized plan.
    """)

    c1, c2 = st.columns(2)
    with c1:
        uploaded_bom_file = st.file_uploader("Upload CAD/Revit Export (BOM)", type=["csv", "xlsx"], key="bom_uploader")
    with c2:
        uploaded_offers_file = st.file_uploader("Upload Vendor Offers", type=["csv", "xlsx"], key="offers_uploader")

    if uploaded_bom_file and uploaded_offers_file:
        try:
            df_bom_raw = pd.read_csv(uploaded_bom_file) if uploaded_bom_file.name.endswith('.csv') else pd.read_excel(uploaded_bom_file)
            df_offers_raw = pd.read_csv(uploaded_offers_file) if uploaded_offers_file.name.endswith('.csv') else pd.read_excel(uploaded_offers_file)
            df_offers, found_offer_cols = map_offer_columns(df_offers_raw.copy())
        except Exception as e:
            st.error(f"Error reading files: {e}")
            st.stop()
            
        files_are_valid = True
        if 'Type Name' not in df_bom_raw.columns:
            st.error("BOM file is missing the required 'Type Name' column.")
            files_are_valid = False
        if 'MFG_PART' not in found_offer_cols or 'PRICE' not in found_offer_cols:
            st.error("Offers file is missing required Part Number ('MFG_PART') and 'PRICE' columns.")
            files_are_valid = False

        if files_are_valid:
            with st.sidebar:
                st.header("‚öôÔ∏è Agent Configuration")
                weights = {
                    'price': st.slider("Price Importance", 0.0, 1.0, 0.5),
                    'stock': st.slider("Stock Importance", 0.0, 1.0, 0.2),
                    'brand': st.slider("Brand Importance", 0.0, 1.0, 0.1)
                }
                # In the sidebar section
                st.session_state.lead_time = st.slider(
                    "Avg. Lead Time (Days)", 
                    1, 
                    30, 
                    st.session_state.get('lead_time', 14), # Get existing value or use 14 as default
                    help="..."
)
            
            if st.button("üöÄ Run Full Analysis", type="primary", use_container_width=True):
                session = get_active_session()
                df_bom = preprocess_bom_data(df_bom_raw, session)
                st.session_state.bom_harmonized = df_bom
                st.session_state.baseline_cost = calculate_baseline_cost(df_bom, df_offers)
                with st.spinner("ü§ñ **Agent active:** Cross-referencing suppliers and calculating scores..."):
                    results_df = calculate_best_offers(df_bom, df_offers, weights)
                    st.session_state.initial_results = results_df
                    st.session_state.final_results = results_df
                    st.session_state.analysis_run = True
                    st.rerun()

    # --- Step 3 & 4: Display Results & Take Action ---
    if st.session_state.analysis_run:
        st.markdown("---")
        st.subheader("üìä Step 3: Review Insights & Optimize Plan")

        initial_df = st.session_state.initial_results
        final_df = st.session_state.final_results
        lead_time = st.session_state.lead_time
        baseline_cost = st.session_state.baseline_cost
        
        initial_cost = (initial_df['PRICE'] * initial_df['bom_QUANTITY']).sum()
        oos_count_initial = initial_df[initial_df['STOCK'] < initial_df['bom_QUANTITY']].shape[0]
        
        st.markdown("#### Initial Proposal Dashboard")
        
        display_kpis(initial_df, baseline_cost, lead_time)
        
        with st.spinner("ü§ñ Generating AI executive summary..."):
            summary_kpis = {"baseline_cost": baseline_cost, "optimized_cost": initial_cost, "estimated_savings": baseline_cost - initial_cost, "out_of_stock_items": oos_count_initial, "project_delay_risk_days": oos_count_initial * lead_time}
            summary = get_ai_summary(get_active_session(), summary_kpis)
            st.session_state.ai_summary = summary
            st.text_area("AI Executive Summary", summary, height=150, help="An AI-generated overview of the analysis.")

        if oos_count_initial > 0:
            if st.button("‚úÖ Apply In-Stock Alternatives", help="Replace out-of-stock items with the best available in-stock options to resolve delays."):
                new_final_df = initial_df.copy()
                for i, row in new_final_df.iterrows():
                    if row.get('stock_status') == 'INSUFFICIENT' and isinstance(row['in_stock_alternative'], dict):
                        alt = row['in_stock_alternative']
                        for key in alt: 
                            new_final_df.loc[i, key] = alt[key]
                st.session_state.final_results = new_final_df
                st.rerun()

            if not final_df.equals(initial_df):
                st.markdown("#### ‚úÖ PROBLEM RESOLVED: Updated Plan Dashboard")
                display_kpis(final_df, baseline_cost, lead_time, initial_cost=initial_cost)

        st.markdown("---")
        
        proposals_tab, smart_routing_tab, data_table_tab, downloads_tab = st.tabs([
            "Key Proposals & Reasoning", 
            "üîÄ Smart Routing", 
            "Full Data Table", 
            "‚¨áÔ∏è Downloads"
        ])

        with proposals_tab:
            st.write("Top 10 proposals from your final plan with detailed quantity and stock information.")
            for i, row in final_df.head(10).iterrows():
                initial_row = initial_df.loc[i]
                with st.container(border=True):
                    is_swapped = row['MFG_PART'] != initial_row['MFG_PART']
                    title_color = "#FFD700" if is_swapped else "#00A1FF"
                    title_icon = "üîÑ" if is_swapped else "‚úÖ"
                    
                    # Stock status indicator
                    stock_status = row.get('stock_status', 'UNKNOWN')
                    status_icon = "‚úÖ" if stock_status == 'SUFFICIENT' else "‚ö†Ô∏è"
                    status_color = "#00FF88" if stock_status == 'SUFFICIENT' else "#FF6B6B"

                    c1, c2 = st.columns([2, 3])
                    with c1:
                        st.markdown(f"**Required:** `{row.get('bom_PART_NUMBER', 'N/A')}`")
                        st.caption(f"Mfr: {row.get('bom_MANUFACTURER', 'N/A')} | **Qty Needed: {int(row.get('bom_QUANTITY', 0))}**")
                        
                        # Show original line IDs
                        if 'bom_ORIGINAL_LINE_IDS' in row and pd.notna(row['bom_ORIGINAL_LINE_IDS']):
                            st.caption(f"üìã Aggregated from BOM lines: {str(row['bom_ORIGINAL_LINE_IDS'])[:50]}...")
                        
                            st.info("üß† AI Harmonization Reasoning")
                            st.info(f"{row.get('bom_HARMONIZATION_REASONING', 'No reasoning available.')}")
                    
                    with c2:
                        st.markdown(f"<h5 style='color: {title_color}; margin-bottom: 0;'>{title_icon} {'Swapped' if is_swapped else ''} Proposal</h5>", unsafe_allow_html=True)
                        st.markdown(f"**`{row.get('MFG_PART', 'N/A')}`** from **{row.get('VENDOR_ID', 'N/A')}**")
                        
                        # Enhanced stock display
                        qty_needed = int(row.get('bom_QUANTITY', 0))
                        qty_available = int(row.get('qty_available', 0))
                        qty_to_order = int(row.get('qty_to_order', 0))
                        qty_shortfall = int(row.get('qty_shortfall', 0))
                        line_total = row.get('PRICE', 0) * qty_to_order
                        
                        # Build shortfall line if needed
                        shortfall_html = f"<p style='margin: 2px 0; color: #FF6B6B;'>‚ö†Ô∏è <b>Shortfall:</b> {qty_shortfall} units</p>" if qty_shortfall > 0 else ""
                        
                        # Render HTML card
                        stock_card_html = f"""
<div style='background-color: #1A1C2A; padding: 10px; border-radius: 5px; border-left: 3px solid {status_color}; margin: 10px 0;'>
    <p style='margin: 2px 0;'>{status_icon} <b>Stock Status:</b> {stock_status}</p>
    <p style='margin: 2px 0;'>üí∞ <b>Unit Price:</b> ${row.get('PRICE', 0):.2f}</p>
    <p style='margin: 2px 0;'>üì¶ <b>Available:</b> {qty_available} units</p>
    <p style='margin: 2px 0;'>üõí <b>To Order:</b> {qty_to_order} units</p>
    {shortfall_html}
    <p style='margin: 2px 0;'>üíµ <b>Line Total:</b> ${line_total:.2f}</p>
</div>
"""
                        st.markdown(stock_card_html, unsafe_allow_html=True)
                        
                        match_confidence = f"Match Confidence: {row.get('match_score', 100):.0f}%" if row.get('match_type') == 'FUZZY' else "Exact Match"
                        st.caption(f"üéØ {match_confidence}")
        
        with smart_routing_tab:
            st.markdown("### üîÄ Smart Routing Recommendations")
            st.info("""
            When a single supplier doesn't have enough stock, the AI agent suggests smart routing options:
            - **Alternative Suppliers**: Find other suppliers with sufficient stock
            - **Split Orders**: Combine multiple suppliers to fulfill your needs
            """)
            
            # Find items with stock issues
            insufficient_items = final_df[final_df['stock_status'] == 'INSUFFICIENT'].copy()
            
            if len(insufficient_items) > 0:
                st.warning(f"‚ö†Ô∏è Found {len(insufficient_items)} items with insufficient stock. See smart routing options below:")
                
                for idx, row in insufficient_items.iterrows():
                    with st.expander(f"üì¶ {row['bom_PART_NUMBER']} - Need {int(row['bom_QUANTITY'])} units, {int(row['qty_shortfall'])} short"):
                        col_a, col_b = st.columns([1, 1])
                        
                        with col_a:
                            st.markdown("**Current Selection:**")
                            st.markdown(f"- Vendor: {row.get('VENDOR_ID', 'N/A')}")
                            st.markdown(f"- Part: {row.get('MFG_PART', 'N/A')}")
                            st.markdown(f"- Available: {int(row.get('qty_available', 0))} units")
                            st.markdown(f"- Price: ${row.get('PRICE', 0):.2f}/unit")
                            st.markdown(f"- Can fulfill: {int(row.get('qty_to_order', 0))} units")
                        
                        with col_b:
                            # Check for in-stock alternative
                            if isinstance(row.get('in_stock_alternative'), dict):
                                alt = row['in_stock_alternative']
                                st.success("**‚úÖ In-Stock Alternative Found:**")
                                st.markdown(f"- Vendor: {alt.get('VENDOR_ID', 'N/A')}")
                                st.markdown(f"- Part: {alt.get('MFG_PART', 'N/A')}")
                                st.markdown(f"- Available: {int(alt.get('qty_available', 0))} units ‚úÖ")
                                st.markdown(f"- Price: ${alt.get('PRICE', 0):.2f}/unit")
                                price_diff = alt.get('PRICE', 0) - row['PRICE']
                                st.markdown(f"- Price difference: ${price_diff:.2f}/unit ({'+' if price_diff > 0 else ''}{price_diff/row['PRICE']*100:.1f}%)")
                            
                            # Check for split order options
                            elif row.get('split_order_options') and len(row['split_order_options']) > 0:
                                st.info("**üîÄ Split Order Options:**")
                                st.markdown(f"Combine the primary supplier with {len(row['split_order_options'])} additional vendor(s):")
                                
                                for j, split_opt in enumerate(row['split_order_options'], 1):
                                    st.markdown(f"**Option {j}:**")
                                    st.markdown(f"- Vendor: {split_opt['vendor']}")
                                    st.markdown(f"- Part: {split_opt['part']}")
                                    st.markdown(f"- Order qty: {split_opt['qty_to_order']} units")
                                    st.markdown(f"- Price: ${split_opt['price']:.2f}/unit")
                                    st.markdown("---")
                            else:
                                st.error("‚ùå No alternative suppliers found with sufficient stock.")
            else:
                st.success("‚úÖ All items have sufficient stock! No routing needed.")
        
        with data_table_tab:
            st.write("This table contains the final, optimized Bill of Materials.")
            st.dataframe(final_df.drop(columns=['in_stock_alternative'], errors='ignore'))
        
        with downloads_tab:
            st.subheader("Download Generated Assets")
            st.download_button(label="üìÑ Download AI Executive Summary (.txt)", data=st.session_state.ai_summary, file_name="ai_summary.txt")
            st.download_button(label="üìÑ Download Initial Proposal (.csv)", data=to_csv(initial_df.drop(columns=['in_stock_alternative'], errors='ignore')), file_name="initial_proposal.csv", mime="text/csv")
            st.download_button(label="üìÑ Download Final Optimized BOM (.csv)", data=to_csv(final_df.drop(columns=['in_stock_alternative'], errors='ignore')), file_name="optimized_bom.csv", mime="text/csv")
    
    st.markdown("---")
    st.subheader("üí¨ Step 5: Chat with the Agent & Generate Report")

    if st.button("Generate Executive Summary"):
        if st.session_state.analysis_run:
            with st.spinner("ü§ñ **Agent active:** Writing your summary..."):
                st.text_area("AI-Generated Summary", st.session_state.ai_summary, height=200)
        else:
            st.warning("Please run the BOM analysis first to generate a summary.")

    if "messages" not in st.session_state:
        st.session_state.messages = []

    for message in st.session_state.messages:
        with st.chat_message(message["role"]): st.markdown(message["content"])

    if prompt := st.chat_input("Ask about the results..."):
        st.session_state.messages.append({"role": "user", "content": prompt})
        with st.chat_message("user"): st.markdown(prompt)

        with st.chat_message("assistant"):
            # Check if analysis has been run
            if not st.session_state.analysis_run or st.session_state.final_results is None:
                response = "‚ö†Ô∏è Please run the BOM analysis first by uploading your files and clicking 'üöÄ Run Full Analysis'. Once the analysis is complete, I'll be able to answer questions about your results."
                st.warning(response)
            else:
                with st.spinner("ü§ñ Thinking..."):
                    session = get_active_session()
                    
                    # Build context from available data
                    available_cols = ['bom_PART_NUMBER', 'PRICE', 'final_score']
                    if 'VENDOR_ID' in st.session_state.final_results.columns:
                        available_cols.append('VENDOR_ID')
                    context_data = st.session_state.final_results[available_cols].head(15).to_json()

                    agent_prompt = f"""You are a helpful BOM Co-Pilot. Answer the user's question based on the provided data context. Be concise. Data: {context_data}. Question: "{prompt}" """
                    sql_command = f"SELECT SNOWFLAKE.CORTEX.COMPLETE('snowflake-arctic', $${agent_prompt}$$) AS response"
                    response = session.sql(sql_command).to_pandas()['RESPONSE'][0]
                    st.markdown(response)
        st.session_state.messages.append({"role": "assistant", "content": response})

with tab2:
    st.subheader("üìÑ Document Q&A")
    st.info("""
        **Upload or paste the text of a document (e.g., technical regulations, contracts) and ask the AI agent questions about it.**
        *Note: For best results with large documents, please copy and paste only the relevant text into the box below.*
    """)

    uploaded_doc = st.file_uploader("Upload a document (.txt)", type="txt", key="doc_uploader")
    if uploaded_doc is not None:
        st.session_state.doc_context = uploaded_doc.read().decode("utf-8")
    
    doc_text = st.text_area("Or, paste the document text here:", height=200, key="doc_text_area", value=st.session_state.doc_context)
    if doc_text:
        st.session_state.doc_context = doc_text

    if st.session_state.doc_context:
        for message in st.session_state.doc_messages:
            with st.chat_message(message["role"]):
                st.markdown(message["content"])

        if prompt := st.chat_input("Ask a question about the document..."):
            st.session_state.doc_messages.append({"role": "user", "content": prompt})
            with st.chat_message("user"):
                st.markdown(prompt)

            with st.chat_message("assistant"):
                with st.spinner("ü§ñ The agent is analyzing the document..."):
                    session = get_active_session()
                    response = get_doc_chat_response(session, st.session_state.doc_context, prompt)
                    st.markdown(response)
            st.session_state.doc_messages.append({"role": "assistant", "content": response})
        
        if st.session_state.doc_messages:
            st.download_button(
                label="‚¨áÔ∏è Download Chat History",
                data=format_chat_history(st.session_state.doc_messages),
                file_name="doc_chat_history.txt"
            )
    else:
        st.warning("Please provide some document text in the box above to activate the chat.")

with tab3:
    st.subheader("üõ°Ô∏è Compliance Sentinel")
    st.info("""
        **Define project standards or legal requirements, and the AI agent will automatically check your BOM for violations.**
        1.  Make sure you have run an analysis in the "BOM Optimizer" tab first.
        2.  Enter your compliance rules in the text box below (one rule per line).
        3.  Click "Run Compliance Check" to get an actionable report.
    """)
    
    if st.session_state.bom_harmonized is not None:
        default_rules = "Fire doors must have a rating of at least 60 minutes.\nCorridor width must be greater than 1.5m.\nAll circular ducts must have a diameter less than 500mm."
        rules_text = st.text_area("Enter Compliance Rules (one per line):", value=default_rules, height=150)

        if st.button("Run Compliance Check", type="primary", use_container_width=True):
            session = get_active_session()
            with st.spinner("ü§ñ **Compliance Sentinel active:** Scanning model against rules..."):
                violations_df = run_compliance_check(session, st.session_state.initial_results, rules_text)
                st.session_state.compliance_results = violations_df
                st.rerun()

        if st.session_state.compliance_results is not None:
            results = st.session_state.compliance_results
            st.markdown("---")
            st.subheader("Compliance Report")
            
            if results.empty:
                st.success("‚úÖ **No violations found!** Your model appears to be compliant with all defined rules.")
            else:
                st.error(f"üö® **{len(results)} violations found!** Please review the report below.")

                # Compliance Chart
                chart_data = results['Rule Violated'].value_counts().reset_index()
                chart_data.columns = ['Rule', 'Count']
                
                chart = alt.Chart(chart_data).mark_bar(
                    cornerRadiusTopLeft=3,
                    cornerRadiusTopRight=3
                ).encode(
                    x=alt.X('Rule:N', sort='-y', title='Compliance Rule'),
                    y=alt.Y('Count:Q', title='Number of Violations'),
                    tooltip=['Rule', 'Count']
                ).properties(
                    title='Violations by Rule'
                )
                st.altair_chart(chart, use_container_width=True)
                
                # Compliance Data Table
                st.dataframe(results)
                
                st.download_button(
                    label="‚¨áÔ∏è Download Compliance Report (.csv)",
                    data=to_csv(results),
                    file_name="compliance_report.csv",
                    mime="text/csv"
                )
    else:
        st.warning("Please upload and run an analysis on a BOM file in the 'BOM Optimizer' tab to enable the Compliance Sentinel.")

