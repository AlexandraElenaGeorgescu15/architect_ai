{
  "gemini:gemini-2.0-flash-exp": {
    "id": "gemini:gemini-2.0-flash-exp",
    "name": "Gemini 2.0 Flash Experimental",
    "provider": "gemini",
    "size_gb": null,
    "vram_required_gb": null,
    "status": "available",
    "is_trained": false,
    "base_model": null,
    "metadata": {
      "api_key_configured": true
    }
  },
  "gemini:gemini-1.5-pro": {
    "id": "gemini:gemini-1.5-pro",
    "name": "Gemini 1.5 Pro",
    "provider": "gemini",
    "size_gb": null,
    "vram_required_gb": null,
    "status": "available",
    "is_trained": false,
    "base_model": null,
    "metadata": {
      "api_key_configured": true
    }
  },
  "gemini:gemini-1.5-flash": {
    "id": "gemini:gemini-1.5-flash",
    "name": "Gemini 1.5 Flash",
    "provider": "gemini",
    "size_gb": null,
    "vram_required_gb": null,
    "status": "available",
    "is_trained": false,
    "base_model": null,
    "metadata": {
      "api_key_configured": true
    }
  },
  "groq:llama-3.3-70b-versatile": {
    "id": "groq:llama-3.3-70b-versatile",
    "name": "Llama 3.3 70B Versatile",
    "provider": "groq",
    "size_gb": null,
    "vram_required_gb": null,
    "status": "available",
    "is_trained": false,
    "base_model": null,
    "metadata": {
      "api_key_configured": true
    }
  },
  "groq:llama-3.1-70b-versatile": {
    "id": "groq:llama-3.1-70b-versatile",
    "name": "Llama 3.1 70B Versatile",
    "provider": "groq",
    "size_gb": null,
    "vram_required_gb": null,
    "status": "available",
    "is_trained": false,
    "base_model": null,
    "metadata": {
      "api_key_configured": true
    }
  },
  "groq:llama-3.1-8b-instant": {
    "id": "groq:llama-3.1-8b-instant",
    "name": "Llama 3.1 8B Instant",
    "provider": "groq",
    "size_gb": null,
    "vram_required_gb": null,
    "status": "available",
    "is_trained": false,
    "base_model": null,
    "metadata": {
      "api_key_configured": true
    }
  },
  "groq:mixtral-8x7b-32768": {
    "id": "groq:mixtral-8x7b-32768",
    "name": "Mixtral 8x7B",
    "provider": "groq",
    "size_gb": null,
    "vram_required_gb": null,
    "status": "available",
    "is_trained": false,
    "base_model": null,
    "metadata": {
      "api_key_configured": true
    }
  },
  "openai:gpt-4-turbo": {
    "id": "openai:gpt-4-turbo",
    "name": "GPT-4 Turbo",
    "provider": "openai",
    "size_gb": null,
    "vram_required_gb": null,
    "status": "available",
    "is_trained": false,
    "base_model": null,
    "metadata": {
      "api_key_configured": true
    }
  },
  "openai:gpt-4": {
    "id": "openai:gpt-4",
    "name": "GPT-4",
    "provider": "openai",
    "size_gb": null,
    "vram_required_gb": null,
    "status": "available",
    "is_trained": false,
    "base_model": null,
    "metadata": {
      "api_key_configured": true
    }
  },
  "openai:gpt-3.5-turbo": {
    "id": "openai:gpt-3.5-turbo",
    "name": "GPT-3.5 Turbo",
    "provider": "openai",
    "size_gb": null,
    "vram_required_gb": null,
    "status": "available",
    "is_trained": false,
    "base_model": null,
    "metadata": {
      "api_key_configured": true
    }
  },
  "anthropic:claude-3-5-sonnet-20241022": {
    "id": "anthropic:claude-3-5-sonnet-20241022",
    "name": "Claude 3.5 Sonnet",
    "provider": "anthropic",
    "size_gb": null,
    "vram_required_gb": null,
    "status": "no_api_key",
    "is_trained": false,
    "base_model": null,
    "metadata": {
      "api_key_configured": false
    }
  },
  "anthropic:claude-3-opus-20240229": {
    "id": "anthropic:claude-3-opus-20240229",
    "name": "Claude 3 Opus",
    "provider": "anthropic",
    "size_gb": null,
    "vram_required_gb": null,
    "status": "no_api_key",
    "is_trained": false,
    "base_model": null,
    "metadata": {
      "api_key_configured": false
    }
  },
  "anthropic:claude-3-sonnet-20240229": {
    "id": "anthropic:claude-3-sonnet-20240229",
    "name": "Claude 3 Sonnet",
    "provider": "anthropic",
    "size_gb": null,
    "vram_required_gb": null,
    "status": "no_api_key",
    "is_trained": false,
    "base_model": null,
    "metadata": {
      "api_key_configured": false
    }
  },
  "ollama:deepseek-coder:6.7b-instruct-q4_K_M": {
    "id": "ollama:deepseek-coder:6.7b-instruct-q4_K_M",
    "name": "deepseek-coder:6.7b-instruct-q4_K_M",
    "provider": "ollama",
    "size_gb": null,
    "vram_required_gb": null,
    "status": "available",
    "is_trained": false,
    "base_model": null,
    "metadata": {
      "size": 4083031689
    }
  },
  "ollama:qwen2.5-coder:7b-instruct-q4_K_M": {
    "id": "ollama:qwen2.5-coder:7b-instruct-q4_K_M",
    "name": "qwen2.5-coder:7b-instruct-q4_K_M",
    "provider": "ollama",
    "size_gb": null,
    "vram_required_gb": null,
    "status": "available",
    "is_trained": false,
    "base_model": null,
    "metadata": {
      "size": 4683087561
    }
  },
  "ollama:mistral-nemo:12b-instruct-2407-q4_K_M": {
    "id": "ollama:mistral-nemo:12b-instruct-2407-q4_K_M",
    "name": "mistral-nemo:12b-instruct-2407-q4_K_M",
    "provider": "ollama",
    "size_gb": null,
    "vram_required_gb": null,
    "status": "available",
    "is_trained": false,
    "base_model": null,
    "metadata": {
      "size": 7477217229
    }
  },
  "ollama:qwen2.5-coder:14b-instruct-q4_K_M": {
    "id": "ollama:qwen2.5-coder:14b-instruct-q4_K_M",
    "name": "qwen2.5-coder:14b-instruct-q4_K_M",
    "provider": "ollama",
    "size_gb": null,
    "vram_required_gb": null,
    "status": "available",
    "is_trained": false,
    "base_model": null,
    "metadata": {
      "size": 8988124298
    }
  },
  "ollama:mistral:7b-instruct": {
    "id": "ollama:mistral:7b-instruct",
    "name": "mistral:7b-instruct",
    "provider": "ollama",
    "size_gb": null,
    "vram_required_gb": null,
    "status": "available",
    "is_trained": false,
    "base_model": null,
    "metadata": {
      "size": 4372824384
    }
  },
  "ollama:codellama:7b-instruct": {
    "id": "ollama:codellama:7b-instruct",
    "name": "codellama:7b-instruct",
    "provider": "ollama",
    "size_gb": null,
    "vram_required_gb": null,
    "status": "available",
    "is_trained": false,
    "base_model": null,
    "metadata": {
      "size": 3825910662
    }
  },
  "ollama:llama3:8b-instruct-q4_K_M": {
    "id": "ollama:llama3:8b-instruct-q4_K_M",
    "name": "llama3:8b-instruct-q4_K_M",
    "provider": "ollama",
    "size_gb": null,
    "vram_required_gb": null,
    "status": "available",
    "is_trained": false,
    "base_model": null,
    "metadata": {
      "size": 4920747238
    }
  },
  "ollama:mistral:7b-instruct-q4_K_M": {
    "id": "ollama:mistral:7b-instruct-q4_K_M",
    "name": "mistral:7b-instruct-q4_K_M",
    "provider": "ollama",
    "size_gb": null,
    "vram_required_gb": null,
    "status": "available",
    "is_trained": false,
    "base_model": null,
    "metadata": {
      "size": 4369387754
    }
  },
  "ollama:mistral:7b": {
    "id": "ollama:mistral:7b",
    "name": "mistral:7b",
    "provider": "ollama",
    "size_gb": null,
    "vram_required_gb": null,
    "status": "available",
    "is_trained": false,
    "base_model": null,
    "metadata": {
      "size": 4372824384
    }
  },
  "ollama:llama3.2:3b": {
    "id": "ollama:llama3.2:3b",
    "name": "llama3.2:3b",
    "provider": "ollama",
    "size_gb": null,
    "vram_required_gb": null,
    "status": "available",
    "is_trained": false,
    "base_model": null,
    "metadata": {
      "size": 2019393189
    }
  },
  "ollama:codellama:7b-instruct-q4_K_M": {
    "id": "ollama:codellama:7b-instruct-q4_K_M",
    "name": "codellama:7b-instruct-q4_K_M",
    "provider": "ollama",
    "size_gb": null,
    "vram_required_gb": null,
    "status": "available",
    "is_trained": false,
    "base_model": null,
    "metadata": {
      "size": 4081107848
    }
  },
  "ollama:llama3:latest": {
    "id": "ollama:llama3:latest",
    "name": "llama3:latest",
    "provider": "ollama",
    "size_gb": null,
    "vram_required_gb": null,
    "status": "available",
    "is_trained": false,
    "base_model": null,
    "metadata": {
      "size": 4661224676
    }
  },
  "ollama:dolphin-llama3:latest": {
    "id": "ollama:dolphin-llama3:latest",
    "name": "dolphin-llama3:latest",
    "provider": "ollama",
    "size_gb": null,
    "vram_required_gb": null,
    "status": "available",
    "is_trained": false,
    "base_model": null,
    "metadata": {
      "size": 4661235994,
      "created_at": "2025-12-11T17:56:33.7412807+02:00"
    }
  },
  "huggingface:zai-org-GLM-4.6": {
    "id": "huggingface:zai-org-GLM-4.6",
    "name": "zai-org/GLM-4.6 (HuggingFace)",
    "provider": "huggingface",
    "size_gb": null,
    "vram_required_gb": null,
    "status": "downloaded",
    "is_trained": false,
    "base_model": null,
    "metadata": {
      "huggingface_id": "zai-org/GLM-4.6",
      "path": "models\\huggingface\\zai-org_GLM-4.6",
      "actual_file_path": "models\\huggingface\\zai-org_GLM-4.6\\models--zai-org--GLM-4.6\\snapshots\\be72194883d968d7923a07e2f61681ea9a2826d1\\config.json",
      "usable_via_transformers": true
    }
  },
  "huggingface:microsoft-Phi-3.5-mini-instruct": {
    "id": "huggingface:microsoft-Phi-3.5-mini-instruct",
    "name": "microsoft/Phi-3.5-mini-instruct (HuggingFace)",
    "provider": "huggingface",
    "size_gb": null,
    "vram_required_gb": null,
    "status": "downloaded",
    "is_trained": false,
    "base_model": null,
    "metadata": {
      "huggingface_id": "microsoft/Phi-3.5-mini-instruct",
      "path": "models\\huggingface\\microsoft_Phi-3.5-mini-instruct",
      "actual_file_path": null,
      "usable_via_transformers": true
    }
  },
  "huggingface:microsoft-Phi-3-mini-4k-instruct": {
    "id": "huggingface:microsoft-Phi-3-mini-4k-instruct",
    "name": "microsoft/Phi-3-mini-4k-instruct (HuggingFace)",
    "provider": "huggingface",
    "size_gb": null,
    "vram_required_gb": null,
    "status": "downloaded",
    "is_trained": false,
    "base_model": null,
    "metadata": {
      "huggingface_id": "microsoft/Phi-3-mini-4k-instruct",
      "path": "models\\huggingface\\microsoft_Phi-3-mini-4k-instruct",
      "actual_file_path": null,
      "usable_via_transformers": true
    }
  },
  "huggingface:mradermacher-BlackSheep-MermaidMistral-22B-i1-GGUF": {
    "id": "huggingface:mradermacher-BlackSheep-MermaidMistral-22B-i1-GGUF",
    "name": "mradermacher/BlackSheep-MermaidMistral-22B-i1-GGUF (HuggingFace)",
    "provider": "huggingface",
    "size_gb": null,
    "vram_required_gb": null,
    "status": "downloaded",
    "is_trained": false,
    "base_model": null,
    "metadata": {
      "huggingface_id": "mradermacher/BlackSheep-MermaidMistral-22B-i1-GGUF",
      "path": "models\\huggingface\\mradermacher_BlackSheep-MermaidMistral-22B-i1-GGUF",
      "actual_file_path": null,
      "usable_via_transformers": true
    }
  },
  "huggingface:microsoft-Phi-4-mini-instruct": {
    "id": "huggingface:microsoft-Phi-4-mini-instruct",
    "name": "microsoft/Phi-4-mini-instruct (HuggingFace)",
    "provider": "huggingface",
    "size_gb": null,
    "vram_required_gb": null,
    "status": "downloaded",
    "is_trained": false,
    "base_model": null,
    "metadata": {
      "huggingface_id": "microsoft/Phi-4-mini-instruct",
      "path": "models\\huggingface\\microsoft_Phi-4-mini-instruct",
      "actual_file_path": null,
      "usable_via_transformers": true
    }
  }
}