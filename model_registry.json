{
  "gemini:gemini-3-pro-preview": {
    "id": "gemini:gemini-3-pro-preview",
    "name": "Gemini 3 Pro (Most Intelligent)",
    "provider": "gemini",
    "size_gb": null,
    "vram_required_gb": null,
    "status": "available",
    "is_trained": false,
    "base_model": null,
    "metadata": {
      "api_key_configured": true
    }
  },
  "gemini:gemini-3-flash-preview": {
    "id": "gemini:gemini-3-flash-preview",
    "name": "Gemini 3 Flash (Balanced)",
    "provider": "gemini",
    "size_gb": null,
    "vram_required_gb": null,
    "status": "available",
    "is_trained": false,
    "base_model": null,
    "metadata": {
      "api_key_configured": true
    }
  },
  "gemini:gemini-2.5-pro": {
    "id": "gemini:gemini-2.5-pro",
    "name": "Gemini 2.5 Pro (Advanced Thinking)",
    "provider": "gemini",
    "size_gb": null,
    "vram_required_gb": null,
    "status": "available",
    "is_trained": false,
    "base_model": null,
    "metadata": {
      "api_key_configured": true
    }
  },
  "gemini:gemini-2.5-flash": {
    "id": "gemini:gemini-2.5-flash",
    "name": "Gemini 2.5 Flash (Best Price-Performance)",
    "provider": "gemini",
    "size_gb": null,
    "vram_required_gb": null,
    "status": "available",
    "is_trained": false,
    "base_model": null,
    "metadata": {
      "api_key_configured": true
    }
  },
  "gemini:gemini-2.5-flash-lite": {
    "id": "gemini:gemini-2.5-flash-lite",
    "name": "Gemini 2.5 Flash-Lite (Ultra Fast)",
    "provider": "gemini",
    "size_gb": null,
    "vram_required_gb": null,
    "status": "available",
    "is_trained": false,
    "base_model": null,
    "metadata": {
      "api_key_configured": true
    }
  },
  "gemini:gemini-2.0-flash": {
    "id": "gemini:gemini-2.0-flash",
    "name": "Gemini 2.0 Flash (Legacy)",
    "provider": "gemini",
    "size_gb": null,
    "vram_required_gb": null,
    "status": "available",
    "is_trained": false,
    "base_model": null,
    "metadata": {
      "api_key_configured": true
    }
  },
  "groq:llama-3.3-70b-versatile": {
    "id": "groq:llama-3.3-70b-versatile",
    "name": "Llama 3.3 70B Versatile",
    "provider": "groq",
    "size_gb": null,
    "vram_required_gb": null,
    "status": "available",
    "is_trained": false,
    "base_model": null,
    "metadata": {
      "api_key_configured": true
    }
  },
  "groq:llama-3.3-70b-specdec": {
    "id": "groq:llama-3.3-70b-specdec",
    "name": "Llama 3.3 70B SpecDec (Fast)",
    "provider": "groq",
    "size_gb": null,
    "vram_required_gb": null,
    "status": "available",
    "is_trained": false,
    "base_model": null,
    "metadata": {
      "api_key_configured": true
    }
  },
  "groq:llama-3.2-90b-vision-preview": {
    "id": "groq:llama-3.2-90b-vision-preview",
    "name": "Llama 3.2 90B Vision",
    "provider": "groq",
    "size_gb": null,
    "vram_required_gb": null,
    "status": "available",
    "is_trained": false,
    "base_model": null,
    "metadata": {
      "api_key_configured": true
    }
  },
  "groq:llama-3.2-11b-vision-preview": {
    "id": "groq:llama-3.2-11b-vision-preview",
    "name": "Llama 3.2 11B Vision",
    "provider": "groq",
    "size_gb": null,
    "vram_required_gb": null,
    "status": "available",
    "is_trained": false,
    "base_model": null,
    "metadata": {
      "api_key_configured": true
    }
  },
  "groq:mixtral-8x7b-32768": {
    "id": "groq:mixtral-8x7b-32768",
    "name": "Mixtral 8x7B",
    "provider": "groq",
    "size_gb": null,
    "vram_required_gb": null,
    "status": "available",
    "is_trained": false,
    "base_model": null,
    "metadata": {
      "api_key_configured": true
    }
  },
  "openai:gpt-4o": {
    "id": "openai:gpt-4o",
    "name": "GPT-4o (Latest)",
    "provider": "openai",
    "size_gb": null,
    "vram_required_gb": null,
    "status": "available",
    "is_trained": false,
    "base_model": null,
    "metadata": {
      "api_key_configured": true
    }
  },
  "openai:gpt-4o-mini": {
    "id": "openai:gpt-4o-mini",
    "name": "GPT-4o Mini (Fast)",
    "provider": "openai",
    "size_gb": null,
    "vram_required_gb": null,
    "status": "available",
    "is_trained": false,
    "base_model": null,
    "metadata": {
      "api_key_configured": true
    }
  },
  "openai:o1": {
    "id": "openai:o1",
    "name": "o1 (Reasoning)",
    "provider": "openai",
    "size_gb": null,
    "vram_required_gb": null,
    "status": "available",
    "is_trained": false,
    "base_model": null,
    "metadata": {
      "api_key_configured": true
    }
  },
  "openai:o1-mini": {
    "id": "openai:o1-mini",
    "name": "o1 Mini (Reasoning Fast)",
    "provider": "openai",
    "size_gb": null,
    "vram_required_gb": null,
    "status": "available",
    "is_trained": false,
    "base_model": null,
    "metadata": {
      "api_key_configured": true
    }
  },
  "openai:gpt-4-turbo": {
    "id": "openai:gpt-4-turbo",
    "name": "GPT-4 Turbo (Legacy)",
    "provider": "openai",
    "size_gb": null,
    "vram_required_gb": null,
    "status": "available",
    "is_trained": false,
    "base_model": null,
    "metadata": {
      "api_key_configured": true
    }
  },
  "anthropic:claude-sonnet-4-20250514": {
    "id": "anthropic:claude-sonnet-4-20250514",
    "name": "Claude Sonnet 4 (Latest)",
    "provider": "anthropic",
    "size_gb": null,
    "vram_required_gb": null,
    "status": "no_api_key",
    "is_trained": false,
    "base_model": null,
    "metadata": {
      "api_key_configured": false
    }
  },
  "anthropic:claude-opus-4-20250514": {
    "id": "anthropic:claude-opus-4-20250514",
    "name": "Claude Opus 4",
    "provider": "anthropic",
    "size_gb": null,
    "vram_required_gb": null,
    "status": "no_api_key",
    "is_trained": false,
    "base_model": null,
    "metadata": {
      "api_key_configured": false
    }
  },
  "anthropic:claude-3-5-sonnet-20241022": {
    "id": "anthropic:claude-3-5-sonnet-20241022",
    "name": "Claude 3.5 Sonnet",
    "provider": "anthropic",
    "size_gb": null,
    "vram_required_gb": null,
    "status": "no_api_key",
    "is_trained": false,
    "base_model": null,
    "metadata": {
      "api_key_configured": false
    }
  },
  "anthropic:claude-3-5-haiku-20241022": {
    "id": "anthropic:claude-3-5-haiku-20241022",
    "name": "Claude 3.5 Haiku (Fast)",
    "provider": "anthropic",
    "size_gb": null,
    "vram_required_gb": null,
    "status": "no_api_key",
    "is_trained": false,
    "base_model": null,
    "metadata": {
      "api_key_configured": false
    }
  },
  "ollama:vicoder-html-32b:latest": {
    "id": "ollama:vicoder-html-32b:latest",
    "name": "vicoder-html-32b:latest",
    "provider": "ollama",
    "size_gb": null,
    "vram_required_gb": null,
    "status": "available",
    "is_trained": false,
    "base_model": null,
    "metadata": {
      "size": 7932161984,
      "created_at": "2026-01-22T08:50:45.6718923+02:00"
    }
  },
  "ollama:mermaid-mistral-22b:latest": {
    "id": "ollama:mermaid-mistral-22b:latest",
    "name": "mermaid-mistral-22b:latest",
    "provider": "ollama",
    "size_gb": null,
    "vram_required_gb": null,
    "status": "available",
    "is_trained": false,
    "base_model": null,
    "metadata": {
      "size": 5267139712,
      "created_at": "2026-01-22T08:48:31.5968641+02:00"
    }
  },
  "ollama:llama3:latest": {
    "id": "ollama:llama3:latest",
    "name": "llama3:latest",
    "provider": "ollama",
    "size_gb": null,
    "vram_required_gb": null,
    "status": "available",
    "is_trained": false,
    "base_model": null,
    "metadata": {
      "size": 4661224676,
      "created_at": "2025-12-19T15:26:47.86752+02:00"
    }
  },
  "ollama:dolphin-llama3:latest": {
    "id": "ollama:dolphin-llama3:latest",
    "name": "dolphin-llama3:latest",
    "provider": "ollama",
    "size_gb": null,
    "vram_required_gb": null,
    "status": "available",
    "is_trained": false,
    "base_model": null,
    "metadata": {
      "size": 4661235994,
      "created_at": "2025-12-11T17:56:33.7412807+02:00"
    }
  },
  "ollama:deepseek-coder:6.7b-instruct-q4_K_M": {
    "id": "ollama:deepseek-coder:6.7b-instruct-q4_K_M",
    "name": "deepseek-coder:6.7b-instruct-q4_K_M",
    "provider": "ollama",
    "size_gb": null,
    "vram_required_gb": null,
    "status": "available",
    "is_trained": false,
    "base_model": null,
    "metadata": {
      "size": 4083031689,
      "created_at": "2025-11-10T19:13:53.5978942+02:00"
    }
  },
  "ollama:qwen2.5-coder:7b-instruct-q4_K_M": {
    "id": "ollama:qwen2.5-coder:7b-instruct-q4_K_M",
    "name": "qwen2.5-coder:7b-instruct-q4_K_M",
    "provider": "ollama",
    "size_gb": null,
    "vram_required_gb": null,
    "status": "available",
    "is_trained": false,
    "base_model": null,
    "metadata": {
      "size": 4683087561,
      "created_at": "2025-11-10T16:30:27.5792301+02:00"
    }
  },
  "ollama:mistral-nemo:12b-instruct-2407-q4_K_M": {
    "id": "ollama:mistral-nemo:12b-instruct-2407-q4_K_M",
    "name": "mistral-nemo:12b-instruct-2407-q4_K_M",
    "provider": "ollama",
    "size_gb": null,
    "vram_required_gb": null,
    "status": "available",
    "is_trained": false,
    "base_model": null,
    "metadata": {
      "size": 7477217229,
      "created_at": "2025-11-10T16:00:57.6572091+02:00"
    }
  },
  "ollama:qwen2.5-coder:14b-instruct-q4_K_M": {
    "id": "ollama:qwen2.5-coder:14b-instruct-q4_K_M",
    "name": "qwen2.5-coder:14b-instruct-q4_K_M",
    "provider": "ollama",
    "size_gb": null,
    "vram_required_gb": null,
    "status": "available",
    "is_trained": false,
    "base_model": null,
    "metadata": {
      "size": 8988124298,
      "created_at": "2025-11-10T15:30:19.6999558+02:00"
    }
  },
  "ollama:mistral:7b-instruct": {
    "id": "ollama:mistral:7b-instruct",
    "name": "mistral:7b-instruct",
    "provider": "ollama",
    "size_gb": null,
    "vram_required_gb": null,
    "status": "available",
    "is_trained": false,
    "base_model": null,
    "metadata": {
      "size": 4372824384,
      "created_at": "2025-11-07T21:07:17.8878757+02:00"
    }
  },
  "ollama:codellama:7b-instruct": {
    "id": "ollama:codellama:7b-instruct",
    "name": "codellama:7b-instruct",
    "provider": "ollama",
    "size_gb": null,
    "vram_required_gb": null,
    "status": "available",
    "is_trained": false,
    "base_model": null,
    "metadata": {
      "size": 3825910662,
      "created_at": "2025-11-07T21:06:37.407377+02:00"
    }
  },
  "ollama:llama3:8b-instruct-q4_K_M": {
    "id": "ollama:llama3:8b-instruct-q4_K_M",
    "name": "llama3:8b-instruct-q4_K_M",
    "provider": "ollama",
    "size_gb": null,
    "vram_required_gb": null,
    "status": "available",
    "is_trained": false,
    "base_model": null,
    "metadata": {
      "size": 4920747238,
      "created_at": "2025-11-06T22:10:27.9895644+02:00"
    }
  },
  "ollama:mistral:7b-instruct-q4_K_M": {
    "id": "ollama:mistral:7b-instruct-q4_K_M",
    "name": "mistral:7b-instruct-q4_K_M",
    "provider": "ollama",
    "size_gb": null,
    "vram_required_gb": null,
    "status": "available",
    "is_trained": false,
    "base_model": null,
    "metadata": {
      "size": 4369387754,
      "created_at": "2025-11-06T14:22:04.7670838+02:00"
    }
  },
  "ollama:mistral:7b": {
    "id": "ollama:mistral:7b",
    "name": "mistral:7b",
    "provider": "ollama",
    "size_gb": null,
    "vram_required_gb": null,
    "status": "available",
    "is_trained": false,
    "base_model": null,
    "metadata": {
      "size": 4372824384,
      "created_at": "2025-11-06T14:18:48.2008403+02:00"
    }
  },
  "ollama:llama3.2:3b": {
    "id": "ollama:llama3.2:3b",
    "name": "llama3.2:3b",
    "provider": "ollama",
    "size_gb": null,
    "vram_required_gb": null,
    "status": "available",
    "is_trained": false,
    "base_model": null,
    "metadata": {
      "size": 2019393189,
      "created_at": "2025-11-06T14:16:00.9161171+02:00"
    }
  },
  "ollama:codellama:7b-instruct-q4_K_M": {
    "id": "ollama:codellama:7b-instruct-q4_K_M",
    "name": "codellama:7b-instruct-q4_K_M",
    "provider": "ollama",
    "size_gb": null,
    "vram_required_gb": null,
    "status": "available",
    "is_trained": false,
    "base_model": null,
    "metadata": {
      "size": 4081107848,
      "created_at": "2025-11-06T14:15:59.0278367+02:00"
    }
  },
  "huggingface:microsoft-Phi-3.5-mini-instruct": {
    "id": "huggingface:microsoft-Phi-3.5-mini-instruct",
    "name": "microsoft/Phi-3.5-mini-instruct (HuggingFace)",
    "provider": "huggingface",
    "size_gb": null,
    "vram_required_gb": null,
    "status": "downloaded",
    "is_trained": false,
    "base_model": null,
    "metadata": {
      "huggingface_id": "microsoft/Phi-3.5-mini-instruct",
      "path": "models\\huggingface\\microsoft_Phi-3.5-mini-instruct",
      "actual_file_path": null,
      "usable_via_transformers": true
    }
  },
  "huggingface:microsoft-Phi-3-mini-4k-instruct": {
    "id": "huggingface:microsoft-Phi-3-mini-4k-instruct",
    "name": "microsoft/Phi-3-mini-4k-instruct (HuggingFace)",
    "provider": "huggingface",
    "size_gb": null,
    "vram_required_gb": null,
    "status": "downloaded",
    "is_trained": false,
    "base_model": null,
    "metadata": {
      "huggingface_id": "microsoft/Phi-3-mini-4k-instruct",
      "path": "models\\huggingface\\microsoft_Phi-3-mini-4k-instruct",
      "actual_file_path": null,
      "usable_via_transformers": true
    }
  },
  "huggingface:mradermacher-BlackSheep-MermaidMistral-22B-i1-GGUF": {
    "id": "huggingface:mradermacher-BlackSheep-MermaidMistral-22B-i1-GGUF",
    "name": "mradermacher/BlackSheep-MermaidMistral-22B-i1-GGUF (HuggingFace)",
    "provider": "huggingface",
    "size_gb": null,
    "vram_required_gb": null,
    "status": "downloaded",
    "is_trained": false,
    "base_model": null,
    "metadata": {
      "huggingface_id": "mradermacher/BlackSheep-MermaidMistral-22B-i1-GGUF",
      "path": "models\\huggingface\\mradermacher_BlackSheep-MermaidMistral-22B-i1-GGUF",
      "actual_file_path": null,
      "usable_via_transformers": true
    }
  },
  "huggingface:microsoft-Phi-4-mini-instruct": {
    "id": "huggingface:microsoft-Phi-4-mini-instruct",
    "name": "microsoft/Phi-4-mini-instruct (HuggingFace)",
    "provider": "huggingface",
    "size_gb": null,
    "vram_required_gb": null,
    "status": "downloaded",
    "is_trained": false,
    "base_model": null,
    "metadata": {
      "huggingface_id": "microsoft/Phi-4-mini-instruct",
      "path": "models\\huggingface\\microsoft_Phi-4-mini-instruct",
      "actual_file_path": null,
      "usable_via_transformers": true
    }
  },
  "huggingface:zai-org-GLM-4.6": {
    "id": "huggingface:zai-org-GLM-4.6",
    "name": "zai-org/GLM-4.6 (HuggingFace)",
    "provider": "huggingface",
    "size_gb": null,
    "vram_required_gb": null,
    "status": "downloaded",
    "is_trained": false,
    "base_model": null,
    "metadata": {
      "huggingface_id": "zai-org/GLM-4.6",
      "path": "models\\huggingface\\zai-org_GLM-4.6",
      "actual_file_path": "models\\huggingface\\zai-org_GLM-4.6\\models--zai-org--GLM-4.6\\snapshots\\be72194883d968d7923a07e2f61681ea9a2826d1\\config.json",
      "usable_via_transformers": true
    }
  },
  "huggingface:mradermacher-ViCoder-html-32B-preview-i1-GGUF": {
    "id": "huggingface:mradermacher-ViCoder-html-32B-preview-i1-GGUF",
    "name": "mradermacher/ViCoder-html-32B-preview-i1-GGUF (HuggingFace)",
    "provider": "huggingface",
    "size_gb": null,
    "vram_required_gb": null,
    "status": "downloaded",
    "is_trained": false,
    "base_model": null,
    "metadata": {
      "huggingface_id": "mradermacher/ViCoder-html-32B-preview-i1-GGUF",
      "path": "models\\huggingface\\mradermacher_ViCoder-html-32B-preview-i1-GGUF",
      "actual_file_path": "models\\huggingface\\mradermacher_ViCoder-html-32B-preview-i1-GGUF\\models--mradermacher--ViCoder-html-32B-preview-i1-GGUF\\snapshots\\87ddaa1b8ad1d5bacff9476e5a538d98ebdb91ec\\ViCoder-html-32B-preview.i1-IQ1_M.gguf",
      "usable_via_transformers": true
    }
  },
  "huggingface:deepseek-ai-DeepSeek-OCR": {
    "id": "huggingface:deepseek-ai-DeepSeek-OCR",
    "name": "deepseek-ai/DeepSeek-OCR (HuggingFace)",
    "provider": "huggingface",
    "size_gb": null,
    "vram_required_gb": null,
    "status": "downloaded",
    "is_trained": false,
    "base_model": null,
    "metadata": {
      "huggingface_id": "deepseek-ai/DeepSeek-OCR",
      "path": "models\\huggingface\\deepseek-ai_DeepSeek-OCR",
      "actual_file_path": "models\\huggingface\\deepseek-ai_DeepSeek-OCR\\models--deepseek-ai--DeepSeek-OCR\\snapshots\\9f30c71f441d010e5429c532364a86705536c53a\\config.json",
      "usable_via_transformers": true
    }
  },
  "ollama:deepseek-ocr:latest": {
    "id": "ollama:deepseek-ocr:latest",
    "name": "deepseek-ocr:latest",
    "provider": "ollama",
    "size_gb": null,
    "vram_required_gb": null,
    "status": "available",
    "is_trained": false,
    "base_model": null,
    "metadata": {
      "size": 6687240356,
      "created_at": "2026-01-26T20:32:26.77897+02:00"
    }
  },
  "huggingface:TheBloke-TinyLlama-1.1B-Chat-v1.0-GGUF": {
    "id": "huggingface:TheBloke-TinyLlama-1.1B-Chat-v1.0-GGUF",
    "name": "TheBloke/TinyLlama-1.1B-Chat-v1.0-GGUF (HuggingFace)",
    "provider": "huggingface",
    "size_gb": null,
    "vram_required_gb": null,
    "status": "downloaded",
    "is_trained": false,
    "base_model": null,
    "metadata": {
      "huggingface_id": "TheBloke/TinyLlama-1.1B-Chat-v1.0-GGUF",
      "path": "models\\huggingface\\TheBloke_TinyLlama-1.1B-Chat-v1.0-GGUF",
      "actual_file_path": "models\\huggingface\\TheBloke_TinyLlama-1.1B-Chat-v1.0-GGUF\\models--TheBloke--TinyLlama-1.1B-Chat-v1.0-GGUF\\snapshots\\52e7645ba7c309695bec7ac98f4f005b139cf465\\tinyllama-1.1b-chat-v1.0.Q4_K_M.gguf",
      "usable_via_transformers": true
    }
  },
  "ollama:tinyllama-1-1b-chat-v1-0": {
    "id": "ollama:tinyllama-1-1b-chat-v1-0",
    "name": "tinyllama-1-1b-chat-v1-0 (from TheBloke/TinyLlama-1.1B-Chat-v1.0-GGUF)",
    "provider": "ollama",
    "size_gb": null,
    "vram_required_gb": null,
    "status": "downloaded",
    "is_trained": false,
    "base_model": null,
    "metadata": {
      "huggingface_id": "TheBloke/TinyLlama-1.1B-Chat-v1.0-GGUF",
      "ollama_name": "tinyllama-1-1b-chat-v1-0",
      "source": "huggingface"
    }
  },
  "ollama:tinyllama-1-1b-chat-v1-0:latest": {
    "id": "ollama:tinyllama-1-1b-chat-v1-0:latest",
    "name": "tinyllama-1-1b-chat-v1-0:latest",
    "provider": "ollama",
    "size_gb": null,
    "vram_required_gb": null,
    "status": "available",
    "is_trained": false,
    "base_model": null,
    "metadata": {
      "size": 668788661,
      "created_at": "2026-01-27T15:16:54.2392441+02:00"
    }
  }
}